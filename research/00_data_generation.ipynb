{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e706934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd8df202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\recommendation-engine\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c616ab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29003aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\recommendation-engine'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a7681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataGenerationConfig:\n",
    "    root_dir: Path\n",
    "    data_dir: Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "551ea2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hybrid_recommender.constants import *\n",
    "from src.hybrid_recommender.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82eca6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self):\n",
    "        config_filepath = CONFIG_FILE_PATH\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_generation_config(self) -> DataGenerationConfig:\n",
    "        config = self.config.data_generation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_generation_config = DataGenerationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_dir=config.data_dir,\n",
    "        )\n",
    "\n",
    "        return data_generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b6a511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "import zipfile\n",
    "from src.hybrid_recommender import logger\n",
    "from src.hybrid_recommender.utils.common import get_size\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import numpy as np\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0ca48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGeneration:\n",
    "    def __init__(self, config: DataGenerationConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    @staticmethod\n",
    "    def shuffle_ids(ids: List[str]) -> List[str]:\n",
    "        \"\"\"Shuffle a list of IDs using numpy's permutation.\n",
    "        \n",
    "        Args:\n",
    "            ids: List of IDs to shuffle\n",
    "            \n",
    "        Returns:\n",
    "            Shuffled list of IDs\n",
    "        \"\"\"\n",
    "        return np.random.permutation(ids)\n",
    "\n",
    "    def _generate_dataset(self, n_rows: int, id_pools: Dict[str, List[str]]) -> Dict[str, Any]:\n",
    "        \"\"\"Generate common dataset structure with random data.\n",
    "        \n",
    "        Args:\n",
    "            n_rows: Number of rows to generate\n",
    "            id_pools: Dictionary containing pools of user_ids, event_ids, and organizer_ids\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing the generated dataset\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'user_id': np.random.choice(self.shuffle_ids(id_pools['user_ids']), n_rows),\n",
    "            'event_id': np.random.choice(self.shuffle_ids(id_pools['event_ids']), n_rows),\n",
    "            'organizer_id': np.random.choice(self.shuffle_ids(id_pools['organizer_ids']), n_rows)\n",
    "        }\n",
    "\n",
    "    def generate_files(self) -> None:\n",
    "        \"\"\"Generate CSV files with booking, comment, and like data if they don't exist.\n",
    "        \n",
    "        Creates DataFrames with random data and saves them to CSV files.\n",
    "        Handles existing files and logging appropriately.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(self.config.data_dir):\n",
    "            os.makedirs(self.config.data_dir, exist_ok=True)\n",
    "            logger.info(f\"Generating data to: {self.config.data_dir}\")\n",
    "            \n",
    "            # Set random seed for reproducibility\n",
    "            np.random.seed(42)\n",
    "            \n",
    "            # Define dataset size and ID pools\n",
    "            n_rows = 100_000\n",
    "            id_pools = {\n",
    "                'user_ids': [str(uuid.uuid4()) for _ in range(5000)],\n",
    "                'event_ids': [str(uuid.uuid4()) for _ in range(10000)],\n",
    "                'organizer_ids': [str(uuid.uuid4()) for _ in range(1000)]\n",
    "            }\n",
    "            \n",
    "            # Generate bookings data\n",
    "            booking_data = self._generate_dataset(n_rows, id_pools)\n",
    "            booking_data['booking_id'] = [str(uuid.uuid4()) for _ in range(n_rows)]\n",
    "            df_booking = pd.DataFrame(booking_data).rename(columns={\n",
    "                'event_id': 'booked_event_id',\n",
    "                'organizer_id': 'booked_event_organizer_id'\n",
    "            })\n",
    "            df_booking.to_csv(os.path.join(self.config.data_dir, 'bookings.csv'), index=False)\n",
    "            \n",
    "            # Generate comments data\n",
    "            comment_data = self._generate_dataset(n_rows, id_pools)\n",
    "            comment_data['comment_id'] = [str(uuid.uuid4()) for _ in range(n_rows)]\n",
    "            df_comment = pd.DataFrame(comment_data).rename(columns={\n",
    "                'event_id': 'commented_event_id',\n",
    "                'organizer_id': 'commented_event_organizer_id'\n",
    "            })\n",
    "            df_comment.to_csv(os.path.join(self.config.data_dir, 'comments.csv'), index=False)\n",
    "            \n",
    "            # Generate likes data\n",
    "            like_data = self._generate_dataset(n_rows, id_pools)\n",
    "            like_data['like_id'] = [str(uuid.uuid4()) for _ in range(n_rows)]\n",
    "            df_like = pd.DataFrame(like_data).rename(columns={\n",
    "                'event_id': 'liked_event_id',\n",
    "                'organizer_id': 'liked_event_organizer_id'\n",
    "            })\n",
    "            df_like.to_csv(os.path.join(self.config.data_dir, 'likes.csv'), index=False)           \n",
    "            \n",
    "            logger.info(\"Generated bookings.csv, comments.csv, and likes.csv with 100,000 rows each.\")\n",
    "        else:\n",
    "            logger.info(f\"Files already exist in: {self.config.data_dir}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33c58e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-18 14:57:32,954: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-06-18 14:57:32,954: INFO: common: created directory at: artifacts]\n",
      "[2025-06-18 14:57:32,954: INFO: common: created directory at: artifacts/data_ingestion]\n",
      "[2025-06-18 14:57:32,954: INFO: 1772966207: Generating data to: artifacts/data_ingestion/generated_data]\n",
      "[2025-06-18 14:57:36,200: INFO: 1772966207: Generated bookings.csv, comments.csv, and likes.csv with 100,000 rows each.]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_generation_config = config.get_data_generation_config()\n",
    "    data_generation = DataGeneration(config=data_generation_config)\n",
    "    data_generation.generate_files()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommendation-engine-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
